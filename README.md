## جمع آوری داده ها : Data preparation.ipynb

بزرگترین چالشی که در این پروژه با آن رو به رو بودم تهیه و جمع آوری داد بود. در واقع با چند روز جستجو در اینترنت دیتاستی که شامل همه ویژگی های مورد نیاز ما باشد رو پیدا نکردم. دیتاست مورد نیاز ما بایددارای ویژگی های زیر باشد:
-	دیتاست دارای همه لیبل های مورد نیاز ما باشد.
-	دیتاست باید به زبان انگلیسی باشد.
-	دیتاست باید دارای تعداد مناسبی از نمونه ها برای هر چه بهتر انجام شدن پروسه آموزش مدل باشد
  
متاسفانه دیتاستی که شامل همه موارد بالا باشد رو پیدا نکردم. بنابراین چاره ای نداشتم جز اینکه تعدادی از بهترین دیتاست ها رو دانلود کنم و عملیات پاکسازی دیتا رو برای هر کدام از این دیتاست ها اجرا کنم. در نهایت 7 جدول دیتاست رو دانلود کردم و این دیتاست ها رو باهم ترکیب کردم تا به داده نهایی برسم.
کلیه عملیات خواندن این 7 دیتاست و پاکسازی هر کدام و ترکیب آنها در فایل Data preparation.ipynb انجام شده است. ترکیب این دیتاست ها برای تشکیل این 5 لیبل انجام شد :
- 0-	Neither
- 1-	Racist
- 2- 	hate_speech
- 3-	offensive_language
- 4-	Xenophobia

تعداد کل داده 71953  میباشد که به تفکیک کلاس های ذکر شده تقسیم بندی شدند. در تلفیق این 7 دیتاست نهایت سعی بنده بر این بود که تعداد نمونه های کلاس های مختلف در یک رنج عددی باشند  تا مدل دچار سوگیری به سمت یک لیبل نشود. دیتاست نهایی با نام DATA.csv ذخیره شد.


## مدل سازی : NLP.ipynb
برای مدل سازی از پلتفرم Google Colab استفاده کردم. دیتاست نهایی رو در Google Drive آپلود کردم و در کولب از آن استفاده کردم. برای تسریع امر مدل سازی از GPU T4 بهره بردم. برای مدل سازی از Tokenizer کتابخانه KERAS استفاده کردم. پس از توکنایز کردن تمام نمونه ها تعداد توکن های هر نمونه رو در یک لیست ذخیره کردم و نموداری از فراوانی تعداد توکن هر نمونه ها رسم کردم. این موضوع برای این است که برای پارامتر max_len بتوانیم عدد مناسبی انتخاب کنیم. 
از آنجایی که تقریبا تمام نمونه ها کمتر از 50 توکن دارند  max_len رو روی عدد 50 تنظیم کردم. این عدد برای ساخت pad_sequences لازم است.
برای انتخاب داده آموزش و داده آزمایش از train_test_split استفاده کردم و 15 درصد کل داده شامل 10793  نمونه رو برای آزمایش جدا کردم ضمنا با stratify=y تعداد نمونه های هر کلاس در داده تست متناسب با نسبت تعداد کلاس ها در داده اصلی انتخاب شدند.
از آنجایی که مسئله ما چند کلاسه میباشد و در لایه پایانی شبکه عصبی از activation='softmax' استفاده کردم لیبل هارا در داده آموزش و داده آزمایش رو با کمک to_categorical از کتابخانه KERAS به اصطلاح OneHotEncode کردم
برای ساخت و معماری مدل ابتدا از لایه Embedding استفاده کردم تا بتوانیم کلمات رو نه به صورت جداگانه که به صورت جمعی ببینیم تا شبکه به درستی تصمیم گیری کند. در مورد لایه دوم از شبکه عصبی RNN و به طور مشخص از لایه GRU استفاده کردم.


## آزمون مدل  : Test.ipynb
برای تشخیص دقت و نمایش نتیجه پیش بینی مدل ابتدا توکنایزر و مدل از پیش ذخیره شده را لود کردم و کل فرایند اماده سازی و توکنایز کردن و پیش بینی مدل رو در تابعی با نام Mahdi_sheykhi_Model خلاصه کردم. کارکرد این تابع به این صورت است که متنی رو دریافت میکند و پس از توکنایز کردن و پیشبینی متن میزان وابستگی متن رو به هر کدام از کلاس ها با عددی بین 0 تا 1 نمایش میدهد 0 به معنای عدم وابستگی متن به کلاس مذکور و 1 به معنای بیشترین تعلق یا وابستگی متن به کلاس مذکور است. که این میزان وابستگی و یا عدم وابستگی با نمودار heatmap از کتابخانه seaborn به نمایش آمده است. به عنوان مثال در ادامه سه متن متفوت به مدل داده شده و مدل ما در عرض 33 میلی ثانیه متن رو پیش بینی میکند و میزان تعلق به هر کلاس رو به نمایش گذاشته است.


